{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unzip dataset folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files extracted to D:/RESEARCH/BCI\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "# Specify the zip file path and the output directory\n",
    "zip_file_path = \"D:/RESEARCH/BCI/BCI_dataset.zip\" # This file contains 2000 pair images.\n",
    "output_dir = \"D:/RESEARCH/BCI\"\n",
    "\n",
    "# Open the zip file and extract its contents\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(output_dir)\n",
    "\n",
    "print(f\"Files extracted to {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take a fraction of dataset to minimize the dataset size. This dataset is already paired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified dataset created with 1,000 pairs (2,000 images) in D:/RESEARCH/BCI/BCI_modified.\n",
      "Train: 800 pairs, Test: 200 pairs.\n"
     ]
    }
   ],
   "source": [
    "# Paths to the original dataset\n",
    "base_dir = \"D:/RESEARCH/BCI/BCI_dataset\"\n",
    "trainA_dir = os.path.join(base_dir, \"trainA\")\n",
    "trainB_dir = os.path.join(base_dir, \"trainB\")\n",
    "\n",
    "# Paths for the modified dataset\n",
    "modified_base_dir = \"D:/RESEARCH/BCI/BCI_modified\"\n",
    "modified_trainA_dir = os.path.join(modified_base_dir, \"trainA\")\n",
    "modified_trainB_dir = os.path.join(modified_base_dir, \"trainB\")\n",
    "modified_testA_dir = os.path.join(modified_base_dir, \"testA\")\n",
    "modified_testB_dir = os.path.join(modified_base_dir, \"testB\")\n",
    "\n",
    "# Create directories for the modified dataset\n",
    "os.makedirs(modified_trainA_dir, exist_ok=True)\n",
    "os.makedirs(modified_trainB_dir, exist_ok=True)\n",
    "os.makedirs(modified_testA_dir, exist_ok=True)\n",
    "os.makedirs(modified_testB_dir, exist_ok=True)\n",
    "\n",
    "# Get list of image pairs (ensure matching files in trainA and trainB)\n",
    "trainA_files = sorted(os.listdir(trainA_dir))\n",
    "trainB_files = sorted(os.listdir(trainB_dir))\n",
    "assert len(trainA_files) == len(trainB_files), \"Mismatch in trainA and trainB file counts.\"\n",
    "\n",
    "# Sample 1,000 pairs\n",
    "sample_size = 1000\n",
    "sample_indices = random.sample(range(len(trainA_files)), sample_size)\n",
    "\n",
    "# Split indices into 80% train and 20% test\n",
    "train_split = int(0.8 * sample_size)\n",
    "train_indices = sample_indices[:train_split]\n",
    "test_indices = sample_indices[train_split:]\n",
    "\n",
    "# Function to copy files to the new dataset\n",
    "def copy_files(indices, srcA, srcB, destA, destB):\n",
    "    for idx in indices:\n",
    "        fileA = trainA_files[idx]\n",
    "        fileB = trainB_files[idx]\n",
    "        shutil.copy(os.path.join(srcA, fileA), os.path.join(destA, fileA))\n",
    "        shutil.copy(os.path.join(srcB, fileB), os.path.join(destB, fileB))\n",
    "\n",
    "# Copy train and test files\n",
    "copy_files(train_indices, trainA_dir, trainB_dir, modified_trainA_dir, modified_trainB_dir)\n",
    "copy_files(test_indices, trainA_dir, trainB_dir, modified_testA_dir, modified_testB_dir)\n",
    "\n",
    "print(f\"Modified dataset created with 1,000 pairs (2,000 images) in {modified_base_dir}.\")\n",
    "print(f\"Train: {len(train_indices)} pairs, Test: {len(test_indices)} pairs.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zipping the modified dataset folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "File size too large, try using force_zip64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\zipfile\\__init__.py:1860\u001b[0m, in \u001b[0;36mZipFile.write\u001b[1;34m(self, filename, arcname, compress_type, compresslevel)\u001b[0m\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m src, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopen(zinfo, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m dest:\n\u001b[1;32m-> 1860\u001b[0m     shutil\u001b[38;5;241m.\u001b[39mcopyfileobj(src, dest, \u001b[38;5;241m1024\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m8\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\shutil.py:204\u001b[0m, in \u001b[0;36mcopyfileobj\u001b[1;34m(fsrc, fdst, length)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m buf \u001b[38;5;241m:=\u001b[39m fsrc_read(length):\n\u001b[1;32m--> 204\u001b[0m     fdst_write(buf)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\zipfile\\__init__.py:1214\u001b[0m, in \u001b[0;36m_ZipWriteFile.write\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compressor:\n\u001b[1;32m-> 1214\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compressor\u001b[38;5;241m.\u001b[39mcompress(data)\n\u001b[0;32m   1215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_size \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Example\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m shutil\u001b[38;5;241m.\u001b[39mmake_archive(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:/RESEARCH/BCI/BCI_modified\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzip\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:/RESEARCH/BCI\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\shutil.py:1161\u001b[0m, in \u001b[0;36mmake_archive\u001b[1;34m(base_name, format, root_dir, base_dir, verbose, dry_run, owner, group, logger)\u001b[0m\n\u001b[0;32m   1158\u001b[0m             os\u001b[38;5;241m.\u001b[39mchdir(root_dir)\n\u001b[0;32m   1160\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1161\u001b[0m     filename \u001b[38;5;241m=\u001b[39m func(base_name, base_dir, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1162\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m save_cwd \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\shutil.py:1040\u001b[0m, in \u001b[0;36m_make_zipfile\u001b[1;34m(base_name, base_dir, verbose, dry_run, logger, owner, group, root_dir)\u001b[0m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(path):\n\u001b[0;32m   1039\u001b[0m     arcname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(arcdirpath, name)\n\u001b[1;32m-> 1040\u001b[0m     zf\u001b[38;5;241m.\u001b[39mwrite(path, arcname)\n\u001b[0;32m   1041\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m logger \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1042\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madding \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m, path)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\zipfile\\__init__.py:1859\u001b[0m, in \u001b[0;36mZipFile.write\u001b[1;34m(self, filename, arcname, compress_type, compresslevel)\u001b[0m\n\u001b[0;32m   1856\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1857\u001b[0m     zinfo\u001b[38;5;241m.\u001b[39m_compresslevel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompresslevel\n\u001b[1;32m-> 1859\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m src, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopen(zinfo, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m dest:\n\u001b[0;32m   1860\u001b[0m     shutil\u001b[38;5;241m.\u001b[39mcopyfileobj(src, dest, \u001b[38;5;241m1024\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m8\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\zipfile\\__init__.py:1237\u001b[0m, in \u001b[0;36m_ZipWriteFile.close\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_zip64:\n\u001b[0;32m   1236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file_size \u001b[38;5;241m>\u001b[39m ZIP64_LIMIT:\n\u001b[1;32m-> 1237\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile size too large, try using force_zip64\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_size \u001b[38;5;241m>\u001b[39m ZIP64_LIMIT:\n\u001b[0;32m   1239\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompressed size too large, try using force_zip64\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: File size too large, try using force_zip64"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.make_archive('D:/RESEARCH/BCI/BCI_modified', 'zip', 'D:/RESEARCH/BCI')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
